{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'   \n",
    "else:\n",
    "    device = 'cpu'  \n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = 'APS360_Project_Dataset/dataset4'\n",
    "\n",
    "# Augmentation transform\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Preprocessing transform (normalization)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Data loading and preprocessing function\n",
    "def load_digits_and_preprocess(base_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, label)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            for img_file in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is not None:\n",
    "                    # Convert to PIL for transformation\n",
    "                    img_pil = Image.fromarray(img)\n",
    "                    # Apply augmentation\n",
    "                    augmented_img = augment_transform(img_pil)\n",
    "                    # Convert back to numpy and resize\n",
    "                    aug_img_np = np.array(augmented_img.permute(1, 2, 0))\n",
    "                    aug_img_np = cv2.resize(aug_img_np, (64, 64))  # Resize to 64x64\n",
    "                    images.append(aug_img_np)\n",
    "                    labels.append(int(label))  # Folder name is the label (0-9)\n",
    "                else:\n",
    "                    print(f\"Warning: Failed to load image {img_path}\")\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def split_data(images, labels, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=test_size, random_state=random_state)\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=val_size, random_state=random_state)\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)  # Rescale if in [0, 1] range\n",
    "        \n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "def create_dataloaders(batch_size, train_images, train_labels, val_images, val_labels, test_images, test_labels):\n",
    "    # Create Dataset instances\n",
    "    train_dataset = DigitDataset(train_images, train_labels, transform=data_transform)\n",
    "    val_dataset = DigitDataset(val_images, val_labels, transform=data_transform)\n",
    "    test_dataset = DigitDataset(test_images, test_labels, transform=data_transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 637 images\n",
      "Validation set: 71 images\n",
      "Test set: 177 images\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "images, labels = load_digits_and_preprocess(dataset_path)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_data(images, labels)\n",
    "\n",
    "# Create DataLoaders with specified batch size\n",
    "batch_size = 8\n",
    "train_loader, val_loader, test_loader = create_dataloaders(batch_size, train_images, train_labels, val_images, val_labels, test_images, test_labels)\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train set: {len(train_loader.dataset)} images\")\n",
    "print(f\"Validation set: {len(val_loader.dataset)} images\")\n",
    "print(f\"Test set: {len(test_loader.dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DigitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)  # 10 classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 2.2067\n",
      "Validation Accuracy: 43.66%\n",
      "Epoch 2/15, Loss: 1.0702\n",
      "Validation Accuracy: 78.87%\n",
      "Epoch 3/15, Loss: 0.4548\n",
      "Validation Accuracy: 80.28%\n",
      "Epoch 4/15, Loss: 0.2285\n",
      "Validation Accuracy: 85.92%\n",
      "Epoch 5/15, Loss: 0.1243\n",
      "Validation Accuracy: 84.51%\n",
      "Epoch 6/15, Loss: 0.1829\n",
      "Validation Accuracy: 70.42%\n",
      "Epoch 7/15, Loss: 0.1412\n",
      "Validation Accuracy: 87.32%\n",
      "Epoch 8/15, Loss: 0.0449\n",
      "Validation Accuracy: 88.73%\n",
      "Epoch 9/15, Loss: 0.0508\n",
      "Validation Accuracy: 84.51%\n",
      "Epoch 10/15, Loss: 0.0206\n",
      "Validation Accuracy: 91.55%\n",
      "Epoch 11/15, Loss: 0.0087\n",
      "Validation Accuracy: 87.32%\n",
      "Epoch 12/15, Loss: 0.0033\n",
      "Validation Accuracy: 92.96%\n",
      "Epoch 13/15, Loss: 0.0015\n",
      "Validation Accuracy: 91.55%\n",
      "Epoch 14/15, Loss: 0.0007\n",
      "Validation Accuracy: 91.55%\n",
      "Epoch 15/15, Loss: 0.0005\n",
      "Validation Accuracy: 91.55%\n",
      "Test Accuracy: 88.14%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = DigitCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)\n",
    "\n",
    "# Test the model\n",
    "test_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
